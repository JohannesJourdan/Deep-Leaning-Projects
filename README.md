# Speech Recognition Emotion

Welcome to DL_Project! This repository focuses on the fascinating problem of recognizing human emotions from speech using deep learning, and provides an interactive interface via Huggingface.

## üöÄ Project Overview

- **Objective:** Accurately classify emotions (e.g., happy, sad, angry, neutral, etc.) from audio speech signals.
- **Solution:** We leverage deep learning models to extract acoustic features and predict emotions with high accuracy.
- **Deployment:** The model is deployed with Huggingface.co, allowing users to upload or record audio and get real-time emotion predictions.

## ‚ú® Features

- Audio preprocessing (silence removal, normalization, MFCC feature extraction)
- Deep learning models (e.g., CNN, RNN, LSTM, or hybrid models)
- Interactive Streamlit app for speech emotion recognition
- User-friendly interface: Upload your audio file or record live speech and see detected emotion instantly
- Visualization of model performance and confusion matrix

## üõ†Ô∏è Tech Stack

- **Python**
- **scikit-learn** (ensemble models)
- **TensorFlow / PyTorch** (deep learning models)
- **librosa** (audio feature extraction)
- **pandas**, **numpy** (data manipulation)
- **Huggingface** ( deployment)
- **matplotlib / seaborn** (text processing, if applicable)
